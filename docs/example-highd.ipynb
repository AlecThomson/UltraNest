{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-dimensional models\n",
    "\n",
    "This tutorial demonstrates:\n",
    "\n",
    "* How to use UltraNest in 100 dimensions.\n",
    "* How to speed up likelihood functions with vectorization\n",
    "* How to write a program with UltraNest.\n",
    "* How to execute on multiple cores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "For simplicity, we integrate a 100-dimensional gaussian:\n",
    "\n",
    "$$ L = -\\frac{1}{2} * \\sum^{100}_{i=1} \\left(x_i-\\frac{1}{2}\\right)^2 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest\n",
    "\n",
    "sampler = ultranest.ReactiveNestedSampler(parameters, vectorized_gauss_likelihood, vectorized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we solve the simpler model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sampler.run(min_num_live_points=400)\n",
    "sampler.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets have a go at the harder problem. We limit the number of evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = sampler2.run(min_num_live_points=400, max_ncalls=2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency is very low. This is not just because of the dimensionality of the problem, but also because of the degeneracies. To make progress, lets use a slice sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest.stepsampler\n",
    "# have to choose the number of steps the slice sampler should take\n",
    "# after first results, this should be increased and checked for consistency.\n",
    "nsteps = 2 * len(parameters2)\n",
    "# create step sampler:\n",
    "sampler2.stepsampler = ultranest.stepsampler.RegionSliceSampler(nsteps=nsteps)\n",
    "# run again:\n",
    "result2 = sampler2.run(min_num_live_points=400)\n",
    "sampler2.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency is now constant (at 1/nsteps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameter posterior probability distribution\n",
    "\n",
    "A classic corner plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import cornerplot\n",
    "cornerplot(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornerplot(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler1.ncall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate whether the results make any sense, we want\n",
    "to look whether the fitted function goes through the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"1-sine fit\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n",
    "\n",
    "\n",
    "t_grid = np.linspace(0, 5, 400)\n",
    "\n",
    "from ultranest.plot import PredictionBand\n",
    "band = PredictionBand(t_grid)\n",
    "\n",
    "# go through the solutions\n",
    "for B, A1, P1, t1 in sampler1.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(sine_model1(t_grid, B=B, A1=A1, P1=P1, t1=t1))\n",
    "\n",
    "band.line(color='k')\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='k', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='gray', alpha=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"2-sine fit\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n",
    "\n",
    "band = PredictionBand(t_grid)\n",
    "\n",
    "# go through the solutions\n",
    "for B, A1, P1, t1, A2, P2, t2 in sampler2.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(sine_model2(t_grid, B=B, A1=A1, P1=P1, t1=t1, A2=A2, P2=P2, t2=t2))\n",
    "\n",
    "band.line(color='k')\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='k', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='gray', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Model comparison\n",
    "\n",
    "We now want to know:\n",
    "\n",
    "**Is the model with 2 components better than the model with one component?**\n",
    "\n",
    "What do we mean by \"better\" (\"it fits better\", \"the second component is significant\")?\n",
    "\n",
    "a) Which model is better at predicting data it has not seen yet?\n",
    "\n",
    "b) Which model is more probably the true one, given this data, and these models (and their parameter spaces)?\n",
    "\n",
    "c) Which model is simplest, but complex enough to capture the information complexity of the data?\n",
    "\n",
    "\n",
    "## Bayesian model comparison\n",
    "\n",
    "Here we will focus on b, and apply Bayesian model comparison. \n",
    "\n",
    "For simplicity, we will assume equal a-prior model probabilities.\n",
    "\n",
    "The Bayes factor is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.exp(result2['logz'] - result1['logz'])\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us, assuming both models are equally probable a-priori, that \n",
    "the 2-sine model is 150 times more probable to be the true model than the 1-sine model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: Bayes factors are influenced by parameter and model priors. It is a good idea to vary them and see how sensitive the result is. Here, the factor is extremely large, so we can be fairly confident that the 2-sine model is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For making decisions, thresholds are needed. They can be calibrated to desired low false decisions rates with simulations (generate data under the simpler model, look at K distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
